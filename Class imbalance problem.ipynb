{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"train_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts=train_df.sum().drop(['Image','PatientId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The class Atelectasis has 106 samples\n",
      " The class Cardiomegaly has 20 samples\n",
      " The class Consolidation has 33 samples\n",
      " The class Edema has 16 samples\n",
      " The class Effusion has 128 samples\n",
      " The class Emphysema has 13 samples\n",
      " The class Fibrosis has 14 samples\n",
      " The class Hernia has 2 samples\n",
      " The class Infiltration has 175 samples\n",
      " The class Mass has 45 samples\n",
      " The class Nodule has 54 samples\n",
      " The class Pleural_Thickening has 21 samples\n",
      " The class Pneumonia has 10 samples\n",
      " The class Pneumothorax has 38 samples\n"
     ]
    }
   ],
   "source": [
    "for column in class_counts.keys():\n",
    "    print(f' The class {column} has {train_df[column].sum()} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot (class_counts.values,class_counts.index,color='b')\n",
    "plt.title('Distribution of classes for training Dataset',fontsize=15)\n",
    "plt.xlabel('Number of patients',fontsize=15)\n",
    "plt.ylabel('Disease',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: \n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#Weighted Loss Function\n",
    "\n",
    "#Generate an array of 4 binary label values , 3 positive and 1 negative \n",
    "\n",
    "y_true = np.array(\n",
    "        [[1],\n",
    "         [1],\n",
    "         [1],\n",
    "         [0]])\n",
    "print(f\"y_true: \\n{y_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_1: \n",
      "[[0.9]\n",
      " [0.9]\n",
      " [0.9]\n",
      " [0.9]]\n",
      "\n",
      "y_pred_2: \n",
      "[[0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]]\n"
     ]
    }
   ],
   "source": [
    "#Two models\n",
    "\n",
    "# the better understand the loss function , you will pretend that you have two models\n",
    "\n",
    "#model 1 alawys outputs a 0.9 for any example that it's given\n",
    "#model 2 alawys outputs a 0.1 for any example that it's given\n",
    "\n",
    "#Make model predictions that are alawys 0/9 for all examples\n",
    "\n",
    "y_pred_1 = 0.9 * np.ones(y_true.shape)\n",
    "print(f\"y_pred_1: \\n{y_pred_1}\")\n",
    "print()\n",
    "y_pred_2 = 0.1 * np.ones(y_true.shape)\n",
    "print(f\"y_pred_2: \\n{y_pred_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem with the regular loss function\n",
    "\n",
    "# The learning goal here is to notice that with a regular loss function ( not a weighted loss) . the model that always output 0.9 has a smallar loss ( performs better ) than model 2 \n",
    "\n",
    "#1/ Here this is model is class imbalance where 3 is normal out of 4 and 1 is mass out of 4 \n",
    "#2/ If the data is 2/2 for both label , in this case the loss is the same for both. that mean the classifer work well.\n",
    "#3/Howe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_reg_1: 2.6187\n"
     ]
    }
   ],
   "source": [
    "loss_reg_1 = -1 * np.sum(y_true * np.log(y_pred_1)) + \\\n",
    "                -1 * np.sum((1 - y_true) * np.log(1 - y_pred_1))\n",
    "print(f\"loss_reg_1: {loss_reg_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_reg_2: 7.0131\n"
     ]
    }
   ],
   "source": [
    "loss_reg_2 = -1 * np.sum(y_true * np.log(y_pred_2)) + \\\n",
    "                -1 * np.sum((1 - y_true) * np.log(1 - y_pred_2))\n",
    "print(f\"loss_reg_2: {loss_reg_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the model 1 always predicts 0.9, the regular loss is 2.6187\n",
      "When the model 2 always predicts 0.1, the regular loss is 7.0131\n"
     ]
    }
   ],
   "source": [
    "print(f\"When the model 1 always predicts 0.9, the regular loss is {loss_reg_1:.4f}\")\n",
    "print(f\"When the model 2 always predicts 0.1, the regular loss is {loss_reg_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the loss function gives a greater loss when the predictions are always 0.1, because the data is imbalanced, and has three labels of 1 but only one label for 0.\n",
    "\n",
    "Given a class imbalance with more positive labels, the regular loss function implies that the model with the higher prediction of 0.9 performs better than the model with the lower prediction of 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a weighted loss treats both models the same\n",
    "With a weighted loss function, you will get the same weighted loss when the predictions are all 0.9 versus when the predictions are all 0.1.  \n",
    "- Notice how a prediction of 0.9 is 0.1 away from the positive label of 1.\n",
    "- Also notice how a prediction of 0.1 is 0.1 away from the negative label of 0\n",
    "- So model 1 and 2 are \"symmetric\" along the midpoint of 0.5, if you plot them on a number line between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Loss Equation\n",
    "Calculate the loss for the zero-th label (column at index 0)\n",
    "\n",
    "- The loss is made up of two terms.  To make it easier to read the code, you will calculate each of these terms separately.  We are giving each of these two terms a name for explanatory purposes, but these are not officially called $loss_{pos}$ or $loss_{neg}$\n",
    "\n",
    "    - $loss_{pos}$: we'll use this to refer to the loss where the actual label is positive (the positive examples).\n",
    "    - $loss_{neg}$: we'll use this to refer to the loss where the actual label is negative (the negative examples).  \n",
    "\n",
    "$$ loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\n",
    "\n",
    "$$loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)})$$\n",
    "\n",
    "$$loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this sample dataset is small enough, you can calculate the positive weight to be used in the weighted loss function.  To get the positive weight, count how many NEGATIVE labels are present, divided by the total number of examples.\n",
    "\n",
    "In this case, there is one negative label, and four total examples.\n",
    "\n",
    "Similarly, the negative weight is the fraction of positive labels.\n",
    "\n",
    "Run the next cell to define positive and negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive weight w_p: 0.25\n",
      "negative weight w_n 0.75\n"
     ]
    }
   ],
   "source": [
    "# calculate the positive weight as the fraction of negative labels\n",
    "w_p = 1/4\n",
    "\n",
    "# calculate the negative weight as the fraction of positive labels\n",
    "w_n = 3/4\n",
    "\n",
    "print(f\"positive weight w_p: {w_p}\")\n",
    "print(f\"negative weight w_n {w_n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 weighted loss\n",
    "Run the next two cells to calculate the two loss terms separately.\n",
    "\n",
    "Here, `loss_1_pos` and `loss_1_neg` are calculated using the `y_pred_1` predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_pos : 0.0790\n"
     ]
    }
   ],
   "source": [
    "loss_1_pos=-1*np.sum(w_p*y_true*np.log(y_pred_1))\n",
    "print(f'loss_1_pos : {loss_1_poss :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_neg : 1.7269\n"
     ]
    }
   ],
   "source": [
    "loss_1_neg=-1*np.sum(w_n * (1-y_true)*np.log(1-y_pred_1))\n",
    "print (f'loss_1_neg :{ loss_1_neg : .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1  1.8060\n"
     ]
    }
   ],
   "source": [
    "#sum positive and negative losses to calculate total loss\n",
    "loss_1=loss_1_pos+loss_1_neg\n",
    "print(f'loss_1 {loss_1 : .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 weighted loss\n",
    "\n",
    "Now do the same calculations for when the predictions are from `y_pred_2'.  Calculate the two terms of the weighted loss function and add them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_2_pos: 1.7269\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\n",
    "loss_2_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_2))\n",
    "print(f\"loss_2_pos: {loss_2_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_neg : 1.7269\n"
     ]
    }
   ],
   "source": [
    "loss_2_neg=-1*np.sum(w_n * (1-y_true)*np.log(1-y_pred_2))\n",
    "print (f'loss_1_neg :{ loss_1_neg : .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1  1.8060\n"
     ]
    }
   ],
   "source": [
    "#sum positive and negative losses to calculate total loss\n",
    "loss_2=loss_2_pos+loss_2_neg\n",
    "print(f'loss_1 {loss_1 : .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model 1 and model 2 weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the model always predicts 0.9, the total loss is 1.8060\n",
      "When the model always predicts 0.1, the total loss is 1.8060\n"
     ]
    }
   ],
   "source": [
    "print(f\"When the model always predicts 0.9, the total loss is {loss_1:.4f}\")\n",
    "print(f\"When the model always predicts 0.1, the total loss is {loss_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you notice?\n",
    "Since you used a weighted loss, the calculated loss is the same whether the model always predicts 0.9 or always predicts 0.1.  \n",
    "\n",
    "You may have also noticed that when you calculate each term of the weighted loss separately, there is a bit of symmetry when comparing between the two sets of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_pos: 0.0790 \t loss_1_neg: 1.7269\n",
      "\n",
      "loss_2_pos: 1.7269 \t loss_2_neg: 0.0790\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss_1_pos: {loss_1_pos:.4f} \\t loss_1_neg: {loss_1_neg:.4f}\")\n",
    "print()\n",
    "print(f\"loss_2_pos: {loss_2_pos:.4f} \\t loss_2_neg: {loss_2_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there is a class imbalance, where there are 3 positive labels but only one negative label, the weighted loss accounts for this by giving more weight to the negative label than to the positive label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Loss for more than one class\n",
    "\n",
    "In this week's assignment, you will calculate the multi-class weighted loss (when there is more than one disease class that your model is learning to predict).  Here, you can practice working with 2D numpy arrays, which will help you implement the multi-class weighted loss in the graded assignment.\n",
    "\n",
    "You will work with a dataset that has two disease classes (two columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the labels (true values) that you will practice with\n",
    "y_true = np.array(\n",
    "        [[1,0],\n",
    "         [1,0],\n",
    "         [1,0],\n",
    "         [1,0],\n",
    "         [0,1]\n",
    "        ])\n",
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing axis=0 or axis=1\n",
    "You will use `numpy.sum` to count the number of times column `0` has the value 0.  \n",
    "First, notice the difference when you set axis=0 versus axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using axis = 0 [4 1]\n",
      "using axis = 1 [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# See what happens when you set axis=0\n",
    "print(f\"using axis = 0 {np.sum(y_true,axis=0)}\")\n",
    "\n",
    "# Compare this to what happens when you set axis=1\n",
    "print(f\"using axis = 1 {np.sum(y_true,axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if you choose `axis=0`, the sum is taken for each of the two columns.  This is what you want to do in this case. If you set `axis=1`, the sum is taken for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the weights\n",
    "Previously, you visually inspected the data to calculate the fraction of negative and positive labels.  Here, you can do this programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the positive weights as the fraction of negative labels (0) for each class (each column)\n",
    "w_p = np.sum(y_true == 0,axis=0) / y_true.shape[0]\n",
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the negative weights as the fraction of positive labels (1) for each class\n",
    "w_n = np.sum(y_true == 1, axis=0) / y_true.shape[0]\n",
    "w_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the assignment, you will train a model to try and make useful predictions.  In order to make this example easier to follow, you will pretend that your model always predicts the same value for every example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model predictions where all predictions are the same\n",
    "y_pred = np.ones(y_true.shape)\n",
    "y_pred[:,0] = 0.3 * y_pred[:,0]\n",
    "y_pred[:,1] = 0.7 * y_pred[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, calculate the two terms that make up the loss function.  Notice that you are working with more than one class (represented by columns).  In this case, there are two classes.\n",
    "\n",
    "Start by calculating the loss for class `0`.\n",
    "\n",
    "$$ loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\n",
    "\n",
    "$$loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)})$$\n",
    "\n",
    "$$loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the zero column for the weights, true values, and predictions that you will use to calculate the loss from the positive predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_p[0]: 0.2\n",
      "y_true[:,0]: [1 1 1 1 0]\n",
      "y_pred[:,0]: [0.3 0.3 0.3 0.3 0.3]\n"
     ]
    }
   ],
   "source": [
    "# Print and view column zero of the weight\n",
    "print(f\"w_p[0]: {w_p[0]}\")\n",
    "print(f\"y_true[:,0]: {y_true[:,0]}\")\n",
    "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0_pos: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss from the positive predictions, for class 0\n",
    "loss_0_pos = -1 * np.sum(w_p[0] * \n",
    "                y_true[:, 0] * \n",
    "                np.log(y_pred[:, 0])\n",
    "              )\n",
    "print(f\"loss_0_pos: {loss_0_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the zero column for the weights, true values, and predictions that you will use to calculate the loss from the negative predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_n[0]: 0.8\n",
      "y_true[:,0]: [1 1 1 1 0]\n",
      "y_pred[:,0]: [0.3 0.3 0.3 0.3 0.3]\n"
     ]
    }
   ],
   "source": [
    "# Print and view column zero of the weight\n",
    "print(f\"w_n[0]: {w_n[0]}\")\n",
    "print(f\"y_true[:,0]: {y_true[:,0]}\")\n",
    "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0_neg: 0.2853\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss from the negative predictions, for class 0\n",
    "loss_0_neg = -1 * np.sum( \n",
    "                w_n[0] * \n",
    "                (1 - y_true[:, 0]) * \n",
    "                np.log(1 - y_pred[:, 0])\n",
    "              )\n",
    "print(f\"loss_0_neg: {loss_0_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0: 1.2485\n"
     ]
    }
   ],
   "source": [
    "# add the two loss terms to get the total loss for class 0\n",
    "loss_0 = loss_0_neg + loss_0_pos\n",
    "print(f\"loss_0: {loss_0:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_pos: 0.2853\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss from the positive predictions, for class 1\n",
    "loss_1_pos = -1 * np.sum(w_p[1] * \n",
    "                y_true[:, 1] * \n",
    "                np.log(y_pred[:, 1])\n",
    "              )\n",
    "print(f\"loss_1_pos: {loss_1_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_neg: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss from the negative predictions, for class 1\n",
    "loss_1_neg = -1 * np.sum( \n",
    "                w_n[1] * \n",
    "                (1 - y_true[:, 1]) * \n",
    "                np.log(1 - y_pred[:, 1])\n",
    "              )\n",
    "print(f\"loss_1_neg: {loss_1_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1: 1.2485\n"
     ]
    }
   ],
   "source": [
    "# add the two loss terms to get the total loss for class 0\n",
    "loss_1 = loss_1_neg + loss_1_pos\n",
    "print(f\"loss_1: {loss_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "The data for the two classes (two columns) as well as the predictions were chosen so that you end up getting the same weighted loss for both categories.  \n",
    " - In general, you will expect to calculate different weighted loss values for each disease category, as the model predictions and data will differ from one category to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this practice relates to and differs from the upcoming graded assignment\n",
    "- In the assignment, you will generalize this to calculating the loss for any number of classes.\n",
    "- Also in the assignment, you will learn how to avoid taking the log of zero by adding a small number (more details will be explained in the assignment).\n",
    "- Note that in the lecture videos and in this lecture notebook, you are taking the **sum** of losses for all examples.  In the assignment, you will take the **average (the mean)** for all examples.\n",
    "- Finally, in the assignment, you will work with \"tensors\" in TensorFlow, so you will use the TensorFlow equivalents of the numpy operations (keras.mean instead of numpy.mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
